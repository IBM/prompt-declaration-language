{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import Client, OpenAI\n",
    "from transformers.utils import get_json_schema\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-nothing\",\n",
    "    base_url=\"http://localhost:11434/v1/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wikipedia(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns the Wikipedia page summary for a given query\n",
    "\n",
    "    Args:\n",
    "        query: the page to search for (default None)\n",
    "    \"\"\"\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "params = get_json_schema(wikipedia)\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"wikipedia\",\n",
    "            \"description\": \"Returns the Wikipedia page summary for a given query\",\n",
    "            \"parameters\": params,\n",
    "            \"strict\": False,\n",
    "        },\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"granite3.1-dense:8b-instruct-q4_K_M\",\n",
    "    messages=[\n",
    "        # {\n",
    "        #     \"role\": \"system\",\n",
    "        #     \"content\": \"You are a helpful assistant that analyzes Python.\",\n",
    "        # },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please list one IBM Research laboratory located in the United States. You should use a tool call.\",\n",
    "        },\n",
    "    ],\n",
    "    # max_tokens=300,\n",
    "    tool_choice=\"auto\",\n",
    "    # {\n",
    "    #     \"type\": \"function\",\n",
    "    #     \"function\": {\"name\": \"wikipedia\"},\n",
    "    # },  # \"required\", # none or auto\n",
    "    temperature=0.0,\n",
    "    logprobs=True,\n",
    "    top_logprobs=1,\n",
    "    timeout=30,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='<tool_call>[{\"arguments\":{\"query\": \"IBM Research lab in the US\"},\"tool_call\":\"wikipedia\"}]', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function output: \n"
     ]
    }
   ],
   "source": [
    "# import ollama\n",
    "from ollama import chat, Message\n",
    "\n",
    "response = chat(\n",
    "    \"granite3.1-dense:8b-instruct-q4_K_M\",\n",
    "    messages=[\n",
    "        Message(\n",
    "            role=\"user\",\n",
    "            content=\"Please list one IBM Research laboratory located in the United States. You should use a tool call.\",\n",
    "        )\n",
    "    ],\n",
    "    tools=[wikipedia],  # Actual function reference\n",
    ")\n",
    "\n",
    "available_functions = {\n",
    "    \"wikipedia\": wikipedia,\n",
    "}\n",
    "\n",
    "for tool in response.message.tool_calls or []:\n",
    "    function_to_call = available_functions.get(tool.function.name)\n",
    "    if function_to_call:\n",
    "        print(\"Function output:\", function_to_call(**tool.function.arguments))\n",
    "    else:\n",
    "        print(\"Function not found:\", tool.function.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='granite3.1-dense:8b-instruct-q4_K_M', created_at='2025-01-06T00:05:23.969485Z', done=True, done_reason='stop', total_duration=1002644417, load_duration=14084917, prompt_eval_count=120, prompt_eval_duration=328000000, eval_count=26, eval_duration=657000000, message=Message(role='assistant', content='', images=None, tool_calls=[ToolCall(function=Function(name='wikipedia', arguments={'query': 'IBM Research - Almaden'}))]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friends=[FriendInfo(name='Ollama', age=22, is_available=False), FriendInfo(name='Alonso', age=23, is_available=True)]\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# Define the schema for the response\n",
    "class FriendInfo(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    is_available: bool\n",
    "\n",
    "\n",
    "class FriendList(BaseModel):\n",
    "    friends: list[FriendInfo]\n",
    "\n",
    "\n",
    "# schema = {'type': 'object', 'properties': {'friends': {'type': 'array', 'items': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'age': {'type': 'integer'}, 'is_available': {'type': 'boolean'}}, 'required': ['name', 'age', 'is_available']}}}, 'required': ['friends']}\n",
    "response = chat(\n",
    "    model=\"granite3.1-dense:8b-instruct-q4_K_M\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I have two friends. The first is Ollama 22 years old busy saving the world, and the second is Alonso 23 years old and wants to hang out. Return a list of friends in JSON format\",\n",
    "        }\n",
    "    ],\n",
    "    format=FriendList.model_json_schema(),  # Use Pydantic to generate the schema or format=schema\n",
    "    options={\"temperature\": 0},  # Make responses more deterministic\n",
    ")\n",
    "\n",
    "# Use Pydantic to validate the response\n",
    "friends_response = FriendList.model_validate_json(response.message.content)\n",
    "print(friends_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
