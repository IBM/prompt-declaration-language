description: Granite Multi-Round Chat
text:
# Define the variable `defs` to contain the parsed multi-prompts.json
- read: ./multi-prompts.json
  parser: json
  def: prompts
  # Type-check multi-prompts.json against a specification
  spec: {prompts: [str]}
  # Don't store these prompts in the PDL context
  contribute: []
# Pass each prompt to the model
- for:
    prompt: ${ prompts.prompts }
  repeat:
    text:
    # Output the question, and add it to the context
    - |

      ${ prompt }
    # Use replicate.com to run the Granite model on the context, outputting the result
    - model: ollama_chat/granite3.2:2b
      parameters:
        # Use no LLM model creativity (0 is the default)
        temperature: 0
role: user