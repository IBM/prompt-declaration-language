description: Hello world showing model chaining
text:
- "Hello\n"
- model: ollama_chat/granite3.2:2b
  parameters:
    # "greedy" sampling tells the LLM to use the most likely token at each step
    # decoding_method: greedy # Not used by Ollama
    # Tell the LLM to stop after generating an exclamation point.
    stop: ['!']
  def: GEN
- "\nDid you say ${ GEN }?\n"
- model: ollama_chat/granite3.2:2b
  parameters:
    # decoding_method: greedy
    stop: ['.']
