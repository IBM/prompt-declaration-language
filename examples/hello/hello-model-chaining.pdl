description: Hello world showing model chaining
text:
- "Hello\n"
- model: ollama/granite-code:8b
  parameters:
    # "greedy" sampling tells the LLM to use the most likely token at each step
    decoding_method: greedy
    # Tell the LLM to stop after generating an exclamation point.
    stop_sequences: '!'
  def: GEN
- "\nDid you say ${ GEN }?\n"
- model: ollama/granite-code:8b
  parameters:
    decoding_method: greedy
    stop_sequences: '.'
