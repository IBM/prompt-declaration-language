description: ReAct pattern from Yao et al., [ICLR 2023](https://openreview.net/forum?id=WE_vluYUL-X)
# See alternative implementation here: https://smith.langchain.com/hub/hwchase17/react-chat
defs:
  react_block:
    function:
      trajectory: { list: obj }
    return:
      text:
        - for:
            trajectory: ${ trajectory }
          # join:
          #   with: "\n"
          repeat:
            text:
              - def: type
                text: ${ trajectory.keys()|first }
                contribute: []
              - if: ${ type == 'question'}
                then: |
                  Question: ${ trajectory[type]|trim }
              - if: ${ type == 'task'}
                then: |
                  Task: ${ trajectory[type]|trim }
              - if: ${ type == 'thought'}
                then: |
                  Tho: ${ trajectory[type]|trim }
              - if: ${ type == 'action'}
                then: |
                  Act: ${ trajectory[type]|trim }
              - if: ${ type == 'observation'}
                then: |
                  Obs: ${ trajectory[type]|trim }
              - if: ${ type not in ['question', 'task', 'thought', 'action', 'observation'] }
                then: "${ type }: ${ trajectory[type]|trim }"
        - "\n"

  react_code_block:
    function:
      trajectory: { list: obj }
    return:
      text:
        - for:
            trajectory: ${ trajectory }
          repeat:
            text:
              - def: type
                text: ${ trajectory.keys()|first }
                contribute: []
              - if: ${ type == 'task'}
                then: |
                  Task:
                  ${ trajectory[type]|trim }
              - if: ${ type == 'thought'}
                then:
                  text:
                    - "\n"
                    - |
                      Assistant:
                      <thought> ${ trajectory[type]|trim } </thought>
              - if: ${ type == 'action'}
                then: |
                  <execute>
                  ${ trajectory[type]|trim }
                  </execute>
              - if: ${ type == 'observation'}
                then:
                  text:
                    - "\n"
                    - |
                      Observation:
                      ${ trajectory[type]|trim }
              - if: ${ type == 'solution'}
                then: |-
                  <solution>
                  ${ trajectory[type]|trim }
                  </solution>
              - if: ${ type not in ['question', 'task', 'thought', 'action', 'observation', 'solution'] }
                then: "${ type }: ${ trajectory[type]|trim }"
        - "\n"

  finish_action:
    data:
      display_name: Finish
      pdl_function:
      description: Respond with the Answer
      parameters:
        - name: answer
          type: string
          description: The answer
      examples: []

  demonstrate_tools:
    function:
      tools: { list: obj }
    return:
      for:
        tool: ${ tools }
      repeat:
        for:
          example: ${ tool.examples }
        repeat:
          call: ${ react_block }
          args:
            trajectory: ${ example }

  granite_prompt_messages:
    text:
      - role: system
        contribute: [context]
        # content: "Knowledge Cutoff Date: April 2024.\nToday's Date: "
        text:
          - "Knowledge Cutoff Date: April 2024.\nToday's Date: "
          - lang: python
            code: |
              from datetime import datetime
              result = datetime.today().strftime('%B %d, %Y.\n')
          - "You are Granite, developed by IBM. You are a helpful AI assistant with access to the following tools. When a tool is required to answer the user's query, respond with <|tool_call|> followed by a JSON list of tools used. If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request."
      - role: tools
        contribute: [context]
        text: "TOOLS"
        #  ${ tools }

  # granite_prompt: |
  #   <|start_of_role|>system<|end_of_role|>Knowledge Cutoff Date: April 2024.
  #   Today's Date: February 09, 2025.
  #   You are Granite, developed by IBM. You are a helpful AI assistant with access to the following tools. When a tool is required to answer the user's query, respond with <|tool_call|> followed by a JSON list of tools used. If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request.<|end_of_text|>
  #   <|start_of_role|>tools<|end_of_role|>[
  #       {
  #           "type": "function",
  #           "function": {
  #               "name": "hello",
  #               "description": "Hellos a planet",
  #               "parameters": {
  #                   "type": "object",
  #                   "properties": {
  #                       "planet": {
  #                           "type": "string",
  #                           "description": "The planet"
  #                       }
  #                   },
  #                   "required": [
  #                       "planet"
  #                   ]
  #               },
  #               "return": {
  #                   "type": "string"
  #               }
  #           }
  #       }
  #   ]<|end_of_text|>
  #   <|start_of_role|>user<|end_of_role|>test<|end_of_text|>

  granite_function_llama_cross: # the default
    text:
      - role: system
        contribute: [context]
        text: |
          You are a helpful assistant with access to the following function calls. Your task is to produce a sequence of function calls necessary to generate response to the user utterance. Use the following function calls as required.

          Respond in the format {"name": function name, "arguments": dictionary of argument name and its value}. Do not use variables.

  #   ${ tools }

  llama_tool_messages:
    text:
      - role: system
        contribute: [context]
        text:
          - "Cutting Knowledge Date: December 2023\nToday Date: "
          - lang: python
            code: |
              from datetime import datetime
              result = datetime.today().strftime('%d %B %Y\n\n')
      - role: system
        text: You are a helpful assistant with tool calling capabilities. When you receive a tool call response, use the output to format an answer to the orginal use question.
        contribute: [context]
      - role: user
        text: |
          Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.

          Respond in the format {"name": function name, "arguments": dictionary of argument name and its value}. Do not use variables.
        contribute: [context]
    # ${ tools }

  # llama_tool: |
  #   <|begin_of_text|><|start_header_id|>system<|end_header_id|>

  #   Cutting Knowledge Date: December 2023
  #   Today Date: 23 July 2024

  #   When you receive a tool call response, use the output to format an answer to the orginal user question.

  #   You are a helpful assistant with tool calling capabilities.<|eot_id|><|start_header_id|>user<|end_header_id|>

  #   Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.

  #   Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}. Do not use variables.

# - if: ${ model == "watsonx/meta-llama/llama-3-1-70b-instruct"}
#           then:
#             text:
#               - role: system
#                 text: You are a helpful assistant with tool calling capabilities. When you receive a tool call response, use the output to format an answer to the orginal use question.
#                 contribute: [context]
#               - role: user
#                 text: |
#                   Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.

#                   Respond in the format {"name": function name, "arguments": dictionary of argument name and its value}. Do not use variables.

#                   ${ tools }
#                 contribute: [context]
#           else:
#             text:
#               - role: system
#                 text: |
#                   You are a helpful assistant with access to the following function calls. Your task is to produce a sequence of function calls necessary to generate response to the user utterance. Use the following function calls as required.

#                   Respond in the format {"name": function name, "arguments": dictionary of argument name and its value}. Do not use variables.

#                   ${ tools }
#                 contribute: [context]

  react:
    function:
      task: str
      model: str
      tools: { list: obj }
      trajectories: { list: list }
    return:
      lastOf:
        - if: ${ system_prompt == "llama3"}
          then:
            text:
              - role: system
                contribute: [context]
                text:
                  - "Cutting Knowledge Date: December 2023\nToday Date: "
                  - lang: python
                    code: |
                      from datetime import datetime
                      result = datetime.today().strftime('%d %B %Y\n\n')
              - role: system
                text: You are a helpful assistant with tool calling capabilities. When you receive a tool call response, use the output to format an answer to the orginal use question.
                contribute: [context]
              - role: user
                text: |
                  Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.

                  Respond in the format {"name": function name, "arguments": dictionary of argument name and its value}. Do not use variables.

                  ${ tools }
                contribute: [context]
        - if: ${ system_prompt  == "granite_llama" }
          then:
            text:
              - role: system
                text: |
                  You are a helpful assistant with access to the following function calls. Your task is to produce a sequence of function calls necessary to generate response to the user utterance. Use the following function calls as required.

                  Respond in the format {"name": function name, "arguments": dictionary of argument name and its value}. Do not use variables.

                  ${ tools }
                contribute: [context]
        - if: ${ system_prompt == "granite_tools" }
          then:
            text:
            - role: system
              contribute: [context]
              text:
                - "Knowledge Cutoff Date: April 2024.\nToday's Date: "
                - lang: python
                  code: |
                    from datetime import datetime
                    result = datetime.today().strftime('%B %d, %Y.\n')
                - |
                  You are Granite, developed by IBM. You are a helpful AI assistant with access to the following tools. When a tool is required to answer the user's query, respond with a JSON object of the tool to use. If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request.

                  ${ tools }
            # - role: tools
            #   contribute: [context]
            #   text: ${ tools }
        - "\n"
        - for:
            traj: ${ trajectories }
          repeat:
            text:
              call: ${ react_block }
              args:
                trajectory: ${ traj }
        - ${ task }
        # - "\n"
        - def: prev_action
          contribute: []
          data: none
        - def: exit
          contribute: []
          data: False
        - repeat:
            text:
              - "\nTho: " # Factor 2: enforcing Tho/Act sections
              - def: thought
                model: "${ model }"
                parameters:
                  stop:
                    - "Act:"
                  max_tokens: 256
                  include_stop_sequence: false
              - "\nAct: "
              - def: action
                model: "${ model }"
                parser: json
                parameters:
                  temperature: 0
                  stop: ["\n", "Obs:", "<|eom_id|>"] # Factor 3: action output, e.g. Llama 3 outputs eom_id special token
                  include_stop_sequence: false
                spec: { name: str, arguments: obj } # Factor 4: granite likes arrays, argument names cannot be enforced #{ expr: str }} # spec: [{ name: str, arguments: obj }]
              - if: ${ action != prev_action }
                then:
                  def: observation
                  if: ${ action.name.lower() != 'finish' }
                  then:
                    text:
                      - "\nObs: "
                      - if: ${ action.name.lower() in pdl_tools }
                        then:
                          call: ${ pdl_tools[action.name.lower()] }
                          args:
                            arguments: ${ action.arguments }
                        else: "Invalid action. Valid actions are ${ (pdl_tools.keys()|list)[:-1]|join(', ') }, and ${ (pdl_tools.keys()|list)[-1] }."
                      - "\n" # Factor 2 #Tho:"
                else:
                  def: exit
                  contribute: []
                  data: True
              - def: prev_action
                contribute: []
                data: ${ action }
          until: ${ action.name.lower() == "finish" or exit }
        - data:
            answer: ${ (action.arguments.answer|default("No answer found."))|trim } # Factor 5: answer argument name. some models really like putting answer in.
        # - data:
        #     answer: "No answer"
