defs:
  # https://github.com/instruct-lab/datagen-pipeline/blob/main/sdg/configs/teacher_config.yaml
  teacher_sys_prompt: You are a very knowledgeable AI Assistant that will faithfully assist the user with their task.
  teacher_model: mistralai/mixtral-8x7b-instruct-v0-1
  teacher_template:
    function:
      sys_prompt: str
      prompt: str
    return: <s> [INST] {{sys_prompt}} {{prompt}} [/INST]
  teacher_stop_token: </s>


  # https://github.com/instruct-lab/datagen-pipeline/blob/main/sdg/configs/question_template_freeform.yaml
  question_template_freeform:
    function:
      num_samples: int
      task_description: str
      icl_question: str
    return:
      data:
        introduction: |
          You are asked to come up with a set of {{num_samples}} diverse questions - {{task_description}}.
        principles: |
          Please follow these guiding principles when generating responses:
          * Use proper grammar and punctuation.
          * Always generate safe and respectful content. Do not generate content that is harmful, abusive, or offensive.
          * Always generate content that is factually accurate and relevant to the prompt.
          * The questions should be clear and human-like.
          * The questions should be diverse and cover a wide range of topics.
          * The questions should not be template-based or generic, it should be very diverse.
          * Simply return the questions, do not return any answers or explanations.
          * Strictly adhere to the prompt and generate responses in the same style and format as the example.
          Use this format to generate the questions: 
          ### Question 1: 
        examples: |
          To better assist you with this task, here is an example:
          ### Question 1: {{icl_question}}
        generation: |
          Now generate {{num_samples}} such questions, remember to follow the principles mentioned above and use the same format as the examples. Remember to use the same style and format as the example above. 
        max_new_tokens: 10000

  # https://github.com/instruct-lab/datagen-pipeline/blob/main/sdg/gen_questions_freeform.py
  question_template:
    function:
      introduction: str
      principles: str
      examples: str
      generation: str
    return: |-
      {{introduction}}
      {{principles}}
      {{examples}}
      {{generation}}

  gen_questions_freeform_inner:
    function:
      num_samples: int
      task_description: str
      icl_question: str
    return:
    - defs:
        prompt_data:
          call: question_template_freeform
          args:
            num_samples: "{{num_samples}}"
            task_description: "{{task_description}}"
            icl_question: "{{icl_question}}"
        prompt_text:
          call: question_template
          args:
            introduction: "{{prompt_data.introduction}}"
            principles: "{{prompt_data.principles}}"
            examples: "{{prompt_data.examples}}"
            generation: "{{prompt_data.generation}}"
        teacher_input:
          call: teacher_template
          args:
            sys_prompt: "{{teacher_sys_prompt}}"
            prompt: "{{prompt_text}}"
        teacher_output:
          # TODO: model: "{{teacher_model}}"
          model: mistralai/mixtral-8x7b-instruct-v0-1
          input: "{{teacher_input}}"
          parameters:
            stop_sequences: ["{{teacher_stop_token}}"]
            include_stop_sequence: false
            # TODO: max_new_tokens: "{{prompt_data.max_new_tokens}}"
            max_new_tokens: 4096
    - lan: python
      code: |
        import re
        raw = """ {{teacher_output}} """
        result = re.findall(r"### Question [0-9]+:\s*([^#\n]+)", raw)

  gen_questions_freeform:
    function:
      seed_examples: Any # TODO: provide meaningful schema
    return:
    - defs:
        list_of_lists:
          for:
            example: "{{seed_examples.seed_examples}}"
          repeat:
            call: gen_questions_freeform_inner
            args:
              num_samples: 5
              task_description: "{{seed_examples.task_description}}"
              icl_question: "{{example.question}}"
        flattened:
          lan: python
          code: result = [q for qs in {{list_of_lists}} for q in qs]
    - data:
        task_description: "{{seed_examples.task_description}}"
        questions: "{{flattened}}"


  # https://github.com/instruct-lab/datagen-pipeline/blob/main/sdg/configs/filter_questions_template.yaml
  filter_questions_template:
    function:
      task_description: str
      question: str
    return:
      data:
        introduction: |
          Please act as an impartial judge and evaluate the questions generated by an AI assistant displayed below. Evaluate whether or not the question is a good question of how AI Assistant should respond to the user's instruction. Please assign a score using a binary 0/1 scale.
        principles: |
          Here are the requirements:
          * A large language model should be able to complete the question. For example, do not ask the assistant to create any visual or audio output. For another example, do not ask the assistant to wake you up at 5pm or set a reminder because it cannot perform any action.
          * The questions should be in English.
          * The questions should be 1 to 2 sentences long and should be properly formatted.
          * The question should not be offensive, abusive, or harmful. It should be safe and respectful.
          * The question should be relevant to the task given - {{task_description}}.
          If the question meets the above requirements, please rate it 1. If not, please rate it 0.
        generation: |
          Begin your evaluation by providing a short explanation. Be as objective as possible. After providing your explanation, you must rate the question on a scale of 0 or 1 as mentioned above by strictly following this format: \"[[rating]]\", for example: \"Rating: [[1]]\"
          Here's the question you need to evaluate:
          {{question}}
        max_new_tokens: 256

  # https://github.com/instruct-lab/datagen-pipeline/blob/main/sdg/filter_questions.py
  filterq_template:
    function:
      introduction: str
      principles: str
      generation: str
    return: |-
      {{introduction}}
      {{principles}}
      {{generation}}

  filter_questions_inner:
    function:
      task_description: str
      question: str
    return:
    - defs:
        prompt_data:
          call: filter_questions_template
          args:
            task_description: "{{task_description}}"
            question: "{{question}}"
        prompt_text:
          call: filterq_template
          args:
            introduction: "{{prompt_data.introduction}}"
            principles: "{{prompt_data.principles}}"
            generation: "{{prompt_data.generation}}"
        teacher_input:
          call: teacher_template
          args:
            sys_prompt: "{{teacher_sys_prompt}}"
            prompt: "{{prompt_text}}"
        teacher_output:
          # TODO: model: "{{teacher_model}}"
          model: mistralai/mixtral-8x7b-instruct-v0-1
          input: "{{teacher_input}}"
          parameters:
            stop_sequences: ["{{teacher_stop_token}}"]
            include_stop_sequence: false
            # TODO: max_new_tokens: "{{prompt_data.max_new_tokens}}"
            max_new_tokens: 256
    - lan: python
      code: |
        import re
        raw = """ {{teacher_output}} """
        match = re.search(r"Rating.*\[\[(\d+\.?\d*)\]\]", raw)
        result = float(match.group(1)) if match else None

  filter_questions:
    function:
      task_description: str
      questions: list[str]
    return:
    - defs:
        list_of_pairs:
          for:
            question: "{{questions}}"
          repeat:
          - def: filter_output
            call: filter_questions_inner
            args:
              task_description: "{{task_description}}"
              question: "{{question}}"
          - data:
              question: "{{question}}"
              keep: "{{filter_output}}"
        filtered:
          lan: python
          code: result = [p["question"] for p in {{list_of_pairs}} if p["keep"]]
    - "{{filtered}}"


document:
- |
  Loading seed examples
  ---------------------
- def: seed_examples # https://github.com/instruct-lab/taxonomy/blob/main/compositional_skills/writing/freeform/jokes/puns/general/qna.yaml
  read: examples/teacher/qna.yaml
  parser: yaml
- |

  Generating questions
  --------------------
- def: generated_questions
  call: gen_questions_freeform
  args:
    seed_examples: "{{seed_examples}}"
- |

  Filtering questions
  -------------------
- call: filter_questions
  args:
    task_description: "{{generated_questions.task_description}}"
    questions: "{{generated_questions.questions}}"
