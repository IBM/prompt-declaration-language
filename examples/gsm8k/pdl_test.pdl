defs:
  RITS_API_KEY:
    lang: python
    code: |
      import os
      result = os.environ["RITS_API_KEY"]
  PDL_schema:
    read: schema.json
    parser: json
text:
- model: openai/ibm-granite/granite-3.1-8b-instruct
  def: answer
  input:
    text:
    - |-
      Question: Write a PDL script that makes a call to a granite model with the prompt "Hello"

      Answer:
      ```
      description: PDL with model call
      text:
      - model: ibm/granite-20b-code-instruct-v2
        input: Hello
      parameters:
          decoding_method: greedy
      ```

      Question: Write a PDL script that makes a call to a model with stop sequence '!' and stop sequences included

      Answer:
      ```
      description: PDL with model call
      text:
      - model: ibm/granite-20b-code-instruct-v2
      parameters:
          decoding_method: greedy
          stop_sequences:
          - '!'
          include_stop_sequence: true
      ```


      Question: Write a PDL script that makes a call to a flan model

      Answer:
      ```
      description: PDL with model call
      text:
      - model: "google/flan-t5-xl"
      parameters:
          decoding_method: greedy
      ```

      Question: Write a PDL program that calls a llama model with temperature 0 to ask what is the weather in Madrid ?


  parameters:
    api_key: ${RITS_API_KEY}
    api_base: https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/granite-3-1-8b-instruct/v1/
    guided_json: ${ PDL_schema }
    guided_decoding_backend: lm-format-enforcer
    extra_headers:
      RITS_API_KEY: ${RITS_API_KEY}
    temperature: 0