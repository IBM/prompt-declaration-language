{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f4ce4a",
   "metadata": {},
   "source": [
    "# Prompt Declaration Language\n",
    "\n",
    "Prompt engineering is difficult: minor variations in prompts have large impacts on the output of LLMs and prompts are model-dependent. In recent years <i> prompt programming languages </i> have emerged to bring discipline to prompt engineering. Many of them are embedded in an imperative language such as Python or TypeScript, making it difficult for users to directly interact with prompts and multi-turn LLM interactions.\n",
    "\n",
    "The Prompt Declaration Language (PDL) is a YAML-based declarative approach to prompt programming, where prompts are at the forefront. PDL facilitates model chaining and tool use, abstracting away the plumbing necessary for such compositions, enables type checking of the input and output of models, and is based on LiteLLM to support a variety of model providers. PDL has been used with RAG, CoT, ReAct, and an agent for solving SWE-bench.\n",
    "\n",
    "You can use PDL stand-alone or from a Python SDK or, as shown here, in a notebook via a notebook extension. In the cell output, model-generated text is rendered in green font, and tool-generated text is rendered in purple font."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc303da",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install 'prompt-declaration-language[examples]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a6874-54d9-4167-82ed-ab2f4fdc0a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pdl.pdl_notebook_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2234ce9",
   "metadata": {},
   "source": [
    "## Model call\n",
    "\n",
    "In PDL, the user specifies step-by-step the shape of data they want to generate. In the following, the `text` construct indicates a text block containing a prompt and a model call. Implicitly, PDL builds a background conversational context (list of role/content) which is used to make model calls. Each model call uses the context built so far as its input prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c62df1-0347-4711-acd7-3892cfd5df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pdl --reset-context\n",
    "description: Model call\n",
    "text: \n",
    "- \"What is the meaning of life?\\n\"\n",
    "- model: replicate/ibm-granite/granite-3.2-8b-instruct\n",
    "  parameters:\n",
    "    stop: [\"!\"]\n",
    "    include_stop_sequence: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d405f8",
   "metadata": {},
   "source": [
    "## Model chaining\n",
    "Model chaining can be done by simply adding to the list of models to call declaratively. Since this cell has the `%%pdl` cell magic without `--reset-context`, it executes in the context created by the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7149b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pdl\n",
    "text:\n",
    "- \"\\nSay it like a poem\\n\"\n",
    "- model: replicate/ibm-granite/granite-3.2-8b-instruct\n",
    "- \"\\n\\nWhat is the most important verse in this poem?\\n\"\n",
    "- model: replicate/ibm-granite/granite-3.2-8b-instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d5a0e1-606e-400a-90ac-6aa650e2eb1e",
   "metadata": {},
   "source": [
    "## Chat templates\n",
    "\n",
    "The following example shows a full-fledged chatbot. In PDL roles are high level annotations and PDL takes care of applying the appropriate chat templates. This example illustrates the use of control structures such as the repeat-until block and reading from files or stdin with the read block. The chatbot repeatedly prompts the user for a query, which it submits to a model, and stops when the query is quit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b2dbc-69fb-4164-9b8b-5817b3f33e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pdl\n",
    "text:\n",
    "- role: system\n",
    "  content: You are Granite, an AI language model developed in 2024. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior.\n",
    "- \"Type `quit` to exit this chatbot.\\n\"\n",
    "- repeat:\n",
    "    text:\n",
    "    - read:\n",
    "      message: \">>> \"\n",
    "      def: query\n",
    "      contribute: [context]\n",
    "    - model: replicate/ibm-granite/granite-3.2-8b-instruct\n",
    "  until: ${ query == 'quit'}\n",
    "  join:\n",
    "    with: \"\\n\\n\"\n",
    "role: user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1bc1a2",
   "metadata": {},
   "source": [
    "## Chat templates\n",
    "\n",
    "The first call to the model in the above program submits the following prompt. PDL takes care of applying the appropriate chat templates and tags, and builds the background context implicitly. Chat templates make your program easier to port across models, since you do not need to specify control tokens by hand. All the user has to do is list the models they want to chain, PDL takes care of the rest.\n",
    "\n",
    "```\n",
    "<|start_of_role|>system<|end_of_role|>You are Granite, an AI language model developed in 2024. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior.<|end_of_text|>\n",
    "<|start_of_role|>user<|end_of_role|>Type `quit` to exit this chatbot.\n",
    "What is APR?<|end_of_text|><|start_of_role|>assistant<|end_of_role|>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa00cfc",
   "metadata": {},
   "source": [
    "## Data pipeline\n",
    "\n",
    "The following program shows a common prompting pattern: read some data, formulate a prompt using that data, submit to a model, and evaluate. In this program, we formulate a prompt for code explanation. The program first defines two variables: `code`, which holds the data we read, and `truth` for the ground truth. It then prints out the source code, formulates a prompts with the data, and calls a model to get an explanation. Finally, a Python code block uses the Levenshtein text distance metric and evaluate the explanation against the ground truth. This pipeline can similarly be applied to an entire data set to produce a jsonl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c323b-ad1a-4434-8732-bc19c5c47883",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pdl --reset-context\n",
    "description: Code explanation example\n",
    "defs:\n",
    "  CODE:\n",
    "    read: ./data.yaml\n",
    "    parser: yaml\n",
    "  TRUTH:\n",
    "    read: ./ground_truth.txt\n",
    "text:\n",
    "- \"\\n${ CODE.source_code }\\n\"\n",
    "- model: replicate/ibm-granite/granite-3.2-8b-instruct\n",
    "  def: EXPLANATION\n",
    "  input: |\n",
    "      Here is some info about the location of the function in the repo.\n",
    "      repo: \n",
    "      ${ CODE.repo_info.repo }\n",
    "      path: ${ CODE.repo_info.path }\n",
    "      Function_name: ${ CODE.repo_info.function_name }\n",
    "\n",
    "\n",
    "      Explain the following code:\n",
    "      ```\n",
    "      ${ CODE.source_code }```\n",
    "- |\n",
    "\n",
    "\n",
    "  EVALUATION:\n",
    "  The similarity (Levenshtein) between this answer and the ground truth is:\n",
    "- def: EVAL\n",
    "  lang: python\n",
    "  code: |\n",
    "    import textdistance\n",
    "    expl = \"\"\"\n",
    "    ${ EXPLANATION }\n",
    "    \"\"\"\n",
    "    truth = \"\"\"\n",
    "    ${ TRUTH }\n",
    "    \"\"\"\n",
    "    result = textdistance.levenshtein.normalized_similarity(expl, truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c40266",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Since prompts are at the forefront, PDL makes users more productive in their trial-and-error with LLMs. Try it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
