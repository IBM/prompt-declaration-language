
defs: 
  reward:
    function:
      response: object
    return:
      lang: python  
      code: |
        import math

        def _get_logprob(value: str, top_logprobs):
            min_logprob = math.inf
            for logprob in top_logprobs:
                if value.startswith(logprob["token"]):
                    return logprob["logprob"]
                min_logprob = min(min_logprob, logprob['logprob'])
            return min_logprob

        def _find_first_token(content: str, logprobs):
            for logprob in reversed(logprobs):
                if content.startswith(logprob["token"]):
                    return logprob
            assert False

        def reward(response):
            content = response['choices'][0]['message']['content']
            if (content != 'true' and content != 'false'):
                raise Exception(f'Wrong value: {content}')

            first_token_logprob = _find_first_token(content, response['choices'][0]['logprobs']['content'])
            top_logprobs = first_token_logprob["top_logprobs"]

            lp_true = _get_logprob("true", top_logprobs)
            lp_false = _get_logprob("false", top_logprobs)
            p_true = math.exp(lp_true)
            p_false = math.exp(lp_false)
            if p_true == 0.0:
                result = -math.inf
            else:
                result = math.log(p_true / (p_true + p_false))

            return result

        result = reward(response)


  llm_as_judge: 
    function:
      model: string
      prompt: string
    return:
      lastOf:
      - model: ${ model }
        input: |
          ${ prompt }
        modelResponse: out
        parameters:
          temperature: 0
          logprobs: true
          top_logprobs: 5
          response_format: {'type': 'json_schema', 'json_schema': {'name': 'schema', 'schema': {'enum': [True, False]}, 'strict': True}}
      - def: score
        data: ${ reward(response=out) }
      retry: 3
      fallback:
        lang: python
        code: |
          raise Exception(f"Llm-as-judge failed!\n judge prompt: {prompt}")

  get_judge_prompt:
    function:
      model: string
      expectation: string
      response: string
    return:
      match: ${ model }
      with: 
      - case: watsonx/ibm/granite-4-h-small
        then: | 
          Your task is to determine if the following statement is true:
                  
          ${ expectation }
          
          Here is the solution: ${ response }

          Is the statement correct? Respond with only ('true'/'false')

      - case: watsonx/openai/gpt-oss-120b
        then: | 
          Your task is to determine if the following statement is true:
                  
          ${ expectation }
          
          Here is the solution: ${ response }

          Is the statement correct? Respond with only ('true'/'false')
      - then: | 
          Your task is to determine if the following statement is true:
                  
          ${ expectation }
          
          Here is the solution: ${ response }

          Is the statement correct? Respond with only ('true'/'false')



  expectations:
    object:
      feedback:
        function:
          expectation: string
          response: 
          pdl_llm_as_judge: string
          pdl_llm_context_transformer: string
        return:
          lastOf:
          - def: score
            call: ${ llm_as_judge }
            args:
              model: ${ pdl_llm_as_judge }
              prompt: ${ get_judge_prompt(pdl_llm_as_judge, expectation, response) }
          - if: ${ score < -0.69 }
            then:
              lastOf:
              - model: ${ pdl_llm_context_transformer }
                def: instruction
                input: |
                  The following requirement is not satisfied, what instruction can be added to get the correct answer?
                  requirement: ${ expectation }
                  Answer with only the instruction.
              - array:
                - ${ score }
                - ${ instruction }
            else:
              ${ score }
          
          





