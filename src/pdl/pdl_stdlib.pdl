
defs: 
  reward:
    function:
      response: 
      evaluation: string
    return:
      defs:
        contents: ${ response['choices'][0].logprobs.content}
      lastOf:
      - for: 
          content: ${ contents }
        repeat: 
          if: ${ content.token == evaluation }
          then: 
            def: top_logprobs
            data: ${ content.top_logprobs }
      - for: 
          tp: ${ top_logprobs }
        repeat: 
          match: ${ tp.token | lower }
          with:
          - case: "true"
            then:
              data: ${ tp.logprob }
              def: lp_y
          - case: "false"
            then: 
              data: ${ tp.logprob }
              def: lp_n
      - lang: python  
        code: |
          import math 
          try:
            lp_y
          except NameError:
            lp_y = -10
          try:
            lp_n
          except NameError:
            lp_n = -10
          result = math.log(math.exp(lp_y) / (math.exp(lp_y) + math.exp(lp_n)))

  expectations:
    object:
      feedback:
        function:
          expectation: string
          response: 
          llm_as_judge: {optional: string}
          model: {optional: string}
        return:
          lastOf:
          - #model: ${ llm_as_judge | default('watsonx/meta-llama/llama-3-3-70b-instruct') }
            model: ${ llm_as_judge | default('watsonx/openai/gpt-oss-120b') }
            def: evaluation
            input: |
              Problem: ${ expectation }
              Solution: ${ response }
              
              Is the solution correct? Respond with only ('true'/'false')
            modelResponse: out
            parameters:
              logprobs: true
              top_logprobs: 5
              response_format: {'type': 'json_schema', 'json_schema': {'name': 'schema', 'schema': {'enum': [True, False]}, 'strict': True}}
          - def: score
            data: ${ reward(response=out, evaluation=evaluation) }
          - if: ${ score < -0.3 }
            then:
              lastOf:
              - model: ${ model | default('ollama_chat/granite3.3:8b') }
                def: instruction
                input: |
                  The following requirement is not satisfied, what instruction can be added to get the correct answer?
                  requirement: ${ expectation }
                  Answer with only the instruction.
              - data:
                  array:
                  - score
                  - instruction
            else:
              score
          
          

  

